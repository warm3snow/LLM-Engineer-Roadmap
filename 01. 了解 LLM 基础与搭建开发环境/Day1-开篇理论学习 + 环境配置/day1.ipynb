{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PyTorch GPU 检测与性能测试\n",
      "============================================================\n",
      "Python 版本: 3.11.11\n",
      "PyTorch 版本: 2.0.1\n",
      "系统信息: Darwin 23.6.0\n",
      "\n",
      "== NVIDIA CUDA 不可用 ==\n",
      "\n",
      "== 当前 PyTorch 不支持 Apple MPS ==\n",
      "\n",
      "== AMD ROCm (HIP) 不可用 ==\n",
      "\n",
      "没有检测到可用的 GPU 设备，仅有 CPU 可用。\n",
      "\n",
      "在 cpu 上测试 2000x2000 矩阵乘法性能...\n",
      "cpu 计算时间: 0.3588 秒\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "def detect_gpus():\n",
    "    \"\"\"检测并返回可用的 GPU 设备\"\"\"\n",
    "    print(f\"Python 版本: {platform.python_version()}\")\n",
    "    print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "    print(f\"系统信息: {platform.system()} {platform.release()}\")\n",
    "    \n",
    "    available_devices = []\n",
    "    \n",
    "    # 检测 CUDA (NVIDIA GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        cuda_device = torch.device(\"cuda\")\n",
    "        available_devices.append(cuda_device)\n",
    "        print(\"\\n== NVIDIA CUDA 可用 ==\")\n",
    "        print(f\"CUDA 版本: {torch.version.cuda}\")\n",
    "        print(f\"GPU 数量: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"  设备 {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            print(f\"    计算能力: {props.major}.{props.minor}\")\n",
    "            print(f\"    总显存: {props.total_memory / 1024**3:.2f} GB\")\n",
    "    else:\n",
    "        print(\"\\n== NVIDIA CUDA 不可用 ==\")\n",
    "    \n",
    "    # 检测 MPS (Apple Silicon GPU)\n",
    "    if hasattr(torch, 'mps') and hasattr(torch.mps, 'is_available'):\n",
    "        if torch.mps.is_available():\n",
    "            mps_device = torch.device(\"mps\")\n",
    "            available_devices.append(mps_device)\n",
    "            print(\"\\n== Apple MPS 可用 ==\")\n",
    "            print(\"注: Apple Silicon GPU 不提供详细硬件信息接口\")\n",
    "        else:\n",
    "            print(\"\\n== Apple MPS 不可用 ==\")\n",
    "    else:\n",
    "        print(\"\\n== 当前 PyTorch 不支持 Apple MPS ==\")\n",
    "    \n",
    "    # 检测 ROCm (AMD GPU) - 通过间接方式\n",
    "    try:\n",
    "        if hasattr(torch, 'hip') and torch.hip.is_available():\n",
    "            hip_device = torch.device(\"hip\")\n",
    "            available_devices.append(hip_device)\n",
    "            print(\"\\n== AMD ROCm (HIP) 可用 ==\")\n",
    "        else:\n",
    "            print(\"\\n== AMD ROCm (HIP) 不可用 ==\")\n",
    "    except:\n",
    "        print(\"\\n== 当前 PyTorch 不支持 AMD ROCm ==\")\n",
    "    \n",
    "    # 始终有 CPU\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    available_devices.append(cpu_device)\n",
    "    \n",
    "    return available_devices\n",
    "\n",
    "def benchmark_device(device, size=5000):\n",
    "    \"\"\"对指定设备进行矩阵乘法性能测试\"\"\"\n",
    "    print(f\"\\n在 {device} 上测试 {size}x{size} 矩阵乘法性能...\")\n",
    "    \n",
    "    # 创建 CPU 张量\n",
    "    a_cpu = torch.randn(size, size)\n",
    "    b_cpu = torch.randn(size, size)\n",
    "    \n",
    "    # 转移到目标设备\n",
    "    try:\n",
    "        a = a_cpu.to(device)\n",
    "        b = b_cpu.to(device)\n",
    "        \n",
    "        # 预热\n",
    "        _ = torch.matmul(a, b)\n",
    "        \n",
    "        # 计时\n",
    "        start = time.time()\n",
    "        c = torch.matmul(a, b)\n",
    "        \n",
    "        # 确保完成计算\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        elif device.type == \"mps\":\n",
    "            torch.mps.synchronize()\n",
    "        elif hasattr(torch, 'hip') and device.type == \"hip\":\n",
    "            torch.hip.synchronize()\n",
    "        \n",
    "        # 如果是 GPU，转回 CPU 以确保操作完成\n",
    "        if device.type != \"cpu\":\n",
    "            _ = c.to(\"cpu\")\n",
    "            \n",
    "        duration = time.time() - start\n",
    "        print(f\"{device} 计算时间: {duration:.4f} 秒\")\n",
    "        return duration\n",
    "    except Exception as e:\n",
    "        print(f\"在 {device} 上测试失败: {e}\")\n",
    "        return None\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PyTorch GPU 检测与性能测试\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 检测可用设备\n",
    "    available_devices = detect_gpus()\n",
    "    \n",
    "    if len(available_devices) <= 1:  # 只有 CPU\n",
    "        print(\"\\n没有检测到可用的 GPU 设备，仅有 CPU 可用。\")\n",
    "        benchmark_device(torch.device(\"cpu\"), size=2000)\n",
    "        return\n",
    "    \n",
    "    # 为每个设备运行基准测试\n",
    "    cpu_time = benchmark_device(torch.device(\"cpu\"), size=2000)\n",
    "    \n",
    "    for device in available_devices:\n",
    "        if device.type != \"cpu\":\n",
    "            gpu_time = benchmark_device(device, size=2000)\n",
    "            if cpu_time and gpu_time:\n",
    "                print(f\"{device} 加速比: {cpu_time/gpu_time:.2f}x\")\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer 输出维度: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# 定义 Transformer 模型\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, nhead, hidden_dim, num_layers, output_dim):\n",
    "        \"\"\"\n",
    "        初始化 Transformer 模型\n",
    "\n",
    "        参数:\n",
    "        input_dim (int): 输入特征维度\n",
    "        nhead (int): 多头注意力头数\n",
    "        hidden_dim (int): 前馈网络的隐藏层维度\n",
    "        num_layers (int): Transformer 编码层数\n",
    "        output_dim (int): 输出维度\n",
    "        \"\"\"\n",
    "        super(TransformerModel, self).__init__()\n",
    "        # 定义一个 Transformer 编码层\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=input_dim, nhead=nhead, dim_feedforward=hidden_dim)\n",
    "        # 将多个编码层堆叠成 Transformer 编码器\n",
    "        self.transformer = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # 定义一个全连接层，将 Transformer 的输出映射到最终的输出维度\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播函数\n",
    "\n",
    "        参数:\n",
    "        x (torch.Tensor): 输入张量，形状为 (seq_len, batch_size, input_dim)\n",
    "\n",
    "        返回:\n",
    "        torch.Tensor: 输出张量，形状为 (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        # 通过 Transformer 编码器处理输入\n",
    "        out = self.transformer(x)  # (seq_len, batch_size, input_dim)\n",
    "        # 对序列维度求平均，聚合序列信息\n",
    "        out = self.fc(out.mean(dim=0))  # (batch_size, input_dim) -> (batch_size, output_dim)\n",
    "        return out\n",
    "\n",
    "# 模型参数\n",
    "input_dim = 10  # 输入特征维度\n",
    "nhead = 2  # 多头注意力头数\n",
    "hidden_dim = 50  # 前馈网络的隐藏层维度\n",
    "num_layers = 2  # Transformer 编码层数\n",
    "output_dim = 1  # 输出维度\n",
    "\n",
    "# 构建模型\n",
    "model = TransformerModel(input_dim=input_dim, nhead=nhead, hidden_dim=hidden_dim, num_layers=num_layers, output_dim=output_dim)\n",
    "\n",
    "# 示例输入数据：seq_len=5, batch_size=32\n",
    "x = torch.randn(5, 32, input_dim)  # 注意输入的形状 (seq_len, batch_size, input_dim)\n",
    "output = model(x)\n",
    "\n",
    "print(\"Transformer 输出维度:\", output.shape)  # (batch_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN 输出维度: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义 RNN 模型\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        初始化 RNN 模型\n",
    "\n",
    "        参数:\n",
    "        input_dim (int): 每个时间步的输入特征维度\n",
    "        hidden_dim (int): 隐层维度\n",
    "        output_dim (int): 输出维度（如回归任务）\n",
    "        \"\"\"\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播函数\n",
    "\n",
    "        参数:\n",
    "        x (torch.Tensor): 输入张量，形状为 (batch_size, seq_len, input_dim)\n",
    "\n",
    "        返回:\n",
    "        torch.Tensor: 输出张量，形状为 (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        out, _ = self.rnn(x)  # (batch_size, seq_len, hidden_dim)\n",
    "        out = self.fc(out[:, -1, :])  # 提取最后一个时间步的输出\n",
    "        return out\n",
    "\n",
    "# 模型参数\n",
    "input_dim = 10  # 每个时间步的输入特征维度\n",
    "hidden_dim = 20  # 隐层维度\n",
    "output_dim = 1  # 输出维度（如回归任务）\n",
    "\n",
    "# 构建模型\n",
    "model = RNNModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "# 示例输入：batch_size=32, seq_len=5\n",
    "# 32个样本，每个样本有5个时间步，每个时间步有10个特征\n",
    "x = torch.randn(32, 5, input_dim)\n",
    "\n",
    "# model(x)  # 前向传播\n",
    "# 运行模型\n",
    "output = model(x)\n",
    "\n",
    "# 注意：RNN 的输入形状为 (batch_size, seq_len, input_dim)\n",
    "# 输出形状为 (batch_size, output_dim)\n",
    "print(\"RNN 输出维度:\", output.shape)  # (batch_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
